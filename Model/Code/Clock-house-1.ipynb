{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import Necessary Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Define paths to the original and test images\n",
        "original_house = '/content/house.png'\n",
        "original_clock = '/content/clock.png'\n",
        "\n",
        "test_house = '/content/house_test.png'\n",
        "test_clock = '/content/clock_test.png'\n",
        "\n",
        "# Ensure the images exist\n",
        "required_images = [original_house, original_clock, test_house, test_clock]\n",
        "for img_path in required_images:\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"Error: {img_path} does not exist. Please upload the image to the specified path.\")\n",
        "        from google.colab import files\n",
        "        files.upload()\n",
        "        break\n",
        "\n",
        "# Directory to save augmented images\n",
        "augmented_dir = '/content/augmented'\n",
        "os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "img_width, img_height = 224, 224  # EfficientNetB0 input size\n",
        "batch_size = 32\n",
        "num_augmented = 850  # Number of augmented images per original image\n",
        "\n",
        "# Create ImageDataGenerator instances for healthy and impaired augmentations\n",
        "healthy_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    brightness_range=[0.8,1.2],\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "impaired_datagen = ImageDataGenerator(\n",
        "    rotation_range=45,  # More rotation to simulate impairments\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    brightness_range=[0.5,1.5],\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Function to augment images\n",
        "def augment_image(image_path, label, datagen, save_dir, prefix, num_augmented):\n",
        "    img = load_img(image_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    aug_iter = datagen.flow(\n",
        "        x,\n",
        "        batch_size=1,\n",
        "        save_to_dir=save_dir,\n",
        "        save_prefix=prefix,\n",
        "        save_format='png'\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i in range(num_augmented):\n",
        "        next(aug_iter)\n",
        "        labels.append(label)\n",
        "    return labels\n",
        "\n",
        "# Create directories for healthy and impaired images\n",
        "healthy_dir = os.path.join(augmented_dir, 'healthy')\n",
        "impaired_dir = os.path.join(augmented_dir, 'impaired')\n",
        "os.makedirs(healthy_dir, exist_ok=True)\n",
        "os.makedirs(impaired_dir, exist_ok=True)\n",
        "\n",
        "# Augment healthy images\n",
        "labels_healthy = []\n",
        "labels_healthy += augment_image(original_house, 0, healthy_datagen, healthy_dir, 'house_healthy', num_augmented)\n",
        "labels_healthy += augment_image(original_clock, 0, healthy_datagen, healthy_dir, 'clock_healthy', num_augmented)\n",
        "\n",
        "# Augment impaired images\n",
        "labels_impaired = []\n",
        "labels_impaired += augment_image(original_house, 1, impaired_datagen, impaired_dir, 'house_impaired', num_augmented)\n",
        "labels_impaired += augment_image(original_clock, 1, impaired_datagen, impaired_dir, 'clock_impaired', num_augmented)\n",
        "\n",
        "# Combine labels\n",
        "labels = labels_healthy + labels_impaired\n",
        "\n",
        "# Collect image file paths and corresponding labels\n",
        "image_paths = []\n",
        "for fname in os.listdir(healthy_dir):\n",
        "    if fname.endswith('.png'):\n",
        "        image_paths.append(os.path.join(healthy_dir, fname))\n",
        "for fname in os.listdir(impaired_dir):\n",
        "    if fname.endswith('.png'):\n",
        "        image_paths.append(os.path.join(impaired_dir, fname))\n",
        "\n",
        "# Shuffle the dataset\n",
        "combined = list(zip(image_paths, labels))\n",
        "random.shuffle(combined)\n",
        "image_paths, labels = zip(*combined)\n",
        "\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Map numerical labels to string labels\n",
        "label_mapping = {0: 'Healthy', 1: 'Impaired'}\n",
        "labels_str = np.array([label_mapping[label] for label in labels])\n",
        "\n",
        "# Create a dataframe with string labels\n",
        "full_df = pd.DataFrame({'filename': image_paths, 'class': labels_str})\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    full_df['filename'], full_df['class'], test_size=0.15, random_state=42, stratify=full_df['class'])\n",
        "\n",
        "# Create separate dataframes for training and validation\n",
        "train_df = pd.DataFrame({'filename': X_train, 'class': y_train})\n",
        "val_df = pd.DataFrame({'filename': X_val, 'class': y_val})\n",
        "\n",
        "print(f'Training samples: {len(train_df)}')\n",
        "print(f'Validation samples: {len(val_df)}')\n",
        "\n",
        "# Define data generators with preprocessing\n",
        "train_datagen_flow = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n",
        "val_datagen_flow = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen_flow.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen_flow.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Class indices:\", train_generator.class_indices)\n",
        "\n",
        "# Build an Advanced CNN Model Using Transfer Learning (Functional API)\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.Input(shape=(img_width, img_height, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n",
        "\n",
        "# Fine-Tune the Model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except the top 20 layers\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define the number of fine-tuning epochs\n",
        "fine_tune_epochs = 10\n",
        "initial_epoch = len(history.history['loss'])\n",
        "total_epochs = initial_epoch + fine_tune_epochs\n",
        "\n",
        "# Continue training with fine-tuning\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=initial_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n",
        "\n",
        "# Load the best model saved during training\n",
        "best_model = tf.keras.models.load_model('/content/best_model.keras')\n",
        "\n",
        "# Function to preprocess and predict a single image\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Batch dimension\n",
        "    return img_array\n",
        "\n",
        "def predict_image(image_path, model):\n",
        "    preprocessed = preprocess_image(image_path)\n",
        "    prediction = model.predict(preprocessed)\n",
        "    class_idx = np.argmax(prediction, axis=1)[0]\n",
        "    class_label = 'Healthy' if class_idx == 0 else 'Impaired'\n",
        "    confidence = prediction[0][class_idx]\n",
        "    return class_label, confidence, prediction\n",
        "\n",
        "# Define test images\n",
        "test_images = [test_house, test_clock]\n",
        "\n",
        "# Function to calculate similarity metrics\n",
        "def calculate_similarity(original_path, test_path):\n",
        "    original = load_img(original_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    test = load_img(test_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "\n",
        "    original = img_to_array(original).astype('uint8')\n",
        "    test = img_to_array(test).astype('uint8')\n",
        "\n",
        "    # Convert to grayscale for SSIM\n",
        "    original_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)\n",
        "    test_gray = cv2.cvtColor(test, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Calculate SSIM\n",
        "    ssim_score = ssim(original_gray, test_gray)\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse_score = np.mean((original - test) ** 2)\n",
        "\n",
        "    return ssim_score, mse_score\n",
        "\n",
        "# Function to visualize comparison\n",
        "def visualize_comparison(original_path, test_path, title):\n",
        "    original = load_img(original_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    test = load_img(test_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "\n",
        "    original = img_to_array(original).astype('uint8')\n",
        "    test = img_to_array(test).astype('uint8')\n",
        "\n",
        "    # Calculate difference\n",
        "    difference = cv2.absdiff(original, test)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    difference_gray = cv2.cvtColor(difference, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply threshold to highlight differences\n",
        "    _, thresh = cv2.threshold(difference_gray, 30, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate SSIM for display\n",
        "    ssim_score, _ = calculate_similarity(original_path, test_path)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(15,5))\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(original.astype('uint8'))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(test.astype('uint8'))\n",
        "    plt.title('Test Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(thresh, cmap='gray')\n",
        "    plt.title(f'Difference Map\\nSSIM: {ssim_score:.4f}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "# Function to generate Grad-CAM heatmap\n",
        "def get_gradcam_heatmap(model, image_path):\n",
        "    # Load and preprocess the image\n",
        "    img = load_img(image_path, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Get the last convolutional layer\n",
        "    last_conv_layer = model.get_layer('efficientnetb0').get_layer('top_conv')\n",
        "\n",
        "    # Create a model that maps the input image to the activations of the last conv layer\n",
        "    grad_model = Model([model.inputs], [last_conv_layer.output, model.output])\n",
        "\n",
        "    # Compute the gradient of the top predicted class for the input image\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        predicted_class = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, predicted_class]\n",
        "\n",
        "    # Compute gradients\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    # Compute guided gradients\n",
        "    guided_grads = grads[0]\n",
        "\n",
        "    # Weigh the outputs of the conv layer with the gradients\n",
        "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs[0]), axis=-1)\n",
        "\n",
        "    # Apply ReLU to the heatmap\n",
        "    heatmap = np.maximum(cam, 0)\n",
        "    max_heat = np.max(heatmap)\n",
        "    if max_heat == 0:\n",
        "        max_heat = 1e-10\n",
        "    heatmap /= max_heat\n",
        "\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(image_path, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
        "    # Load the original image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (img_width, img_height))\n",
        "\n",
        "    # Resize heatmap to match the image size\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Convert to RGB\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap_colored = cv2.applyColorMap(heatmap, colormap)\n",
        "\n",
        "    # Superimpose the heatmap on the image\n",
        "    superimposed_img = cv2.addWeighted(heatmap_colored, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    # Convert BGR to RGB for displaying\n",
        "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function to generate analysis report\n",
        "def generate_analysis_report(original_path, test_path, model):\n",
        "    # Determine the drawing type\n",
        "    if 'house' in test_path.lower():\n",
        "        title = 'House Drawing Analysis'\n",
        "    elif 'clock' in test_path.lower():\n",
        "        title = 'Clock Drawing Analysis'\n",
        "    else:\n",
        "        title = 'Drawing Analysis'\n",
        "\n",
        "    # Predict label and confidence\n",
        "    label, conf, pred = predict_image(test_path, model)\n",
        "\n",
        "    # Calculate similarity metrics\n",
        "    ssim_score, mse_score = calculate_similarity(original_path, test_path)\n",
        "\n",
        "    # Display similarity metrics\n",
        "    print(f'--- {title} ---')\n",
        "    print(f'Predicted Label: {label} with confidence {conf:.2f}')\n",
        "    print(f'SSIM Score: {ssim_score:.4f}')\n",
        "    print(f'MSE Score: {mse_score:.2f}')\n",
        "    print('\\n')\n",
        "\n",
        "    # Visualize comparison\n",
        "    visualize_comparison(original_path, test_path, title)\n",
        "\n",
        "    # Generate Grad-CAM heatmap\n",
        "    try:\n",
        "        heatmap = get_gradcam_heatmap(model, test_path)\n",
        "        print('Grad-CAM Heatmap:')\n",
        "        display_gradcam(test_path, heatmap)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Grad-CAM: {e}\")\n",
        "\n",
        "    # Provide textual analysis\n",
        "    if label == 'Impaired':\n",
        "        print(\"Analysis: The drawing shows significant deviations from the original, indicating possible cognitive impairments associated with Alzheimer's disease.\")\n",
        "    else:\n",
        "        print(\"Analysis: The drawing closely resembles the original, suggesting no significant cognitive impairments detected.\")\n",
        "    print('\\n' + '='*80 + '\\n')\n",
        "\n",
        "# Generate analysis reports for test images\n",
        "for test_img in test_images:\n",
        "    if 'house' in test_img.lower():\n",
        "        original_img = original_house\n",
        "    elif 'clock' in test_img.lower():\n",
        "        original_img = original_clock\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    generate_analysis_report(original_img, test_img, best_model)\n",
        "\n",
        "# Plot Training and Validation Metrics\n",
        "def plot_training_history(history, fine_tune_history=None):\n",
        "    plt.figure(figsize=(14,6))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    epochs_range = range(len(history.history['accuracy']))\n",
        "    plt.plot(epochs_range, history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "\n",
        "    if fine_tune_history:\n",
        "        fine_tune_epochs_range = range(len(history.history['accuracy']), len(history.history['accuracy']) + len(fine_tune_history.history['accuracy']))\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['accuracy'], label='Fine-Tune Train Accuracy')\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['val_accuracy'], label='Fine-Tune Validation Accuracy')\n",
        "\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs_range, history.history['loss'], label='Train Loss')\n",
        "    plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss')\n",
        "\n",
        "    if fine_tune_history:\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['loss'], label='Fine-Tune Train Loss')\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['val_loss'], label='Fine-Tune Validation Loss')\n",
        "\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training history\n",
        "plot_training_history(history, history_fine)\n"
      ],
      "metadata": {
        "id": "1uziS4jmicWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (optional, if you're saving or loading files from Google Drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import Necessary Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Define paths to the original and test images\n",
        "original_house = '/content/house.png'\n",
        "original_clock = '/content/clock.png'\n",
        "\n",
        "test_house = '/content/house_test.png'\n",
        "test_clock = '/content/clock_test.png'\n",
        "\n",
        "# Ensure the images exist\n",
        "required_images = [original_house, original_clock, test_house, test_clock]\n",
        "for img_path in required_images:\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"Error: {img_path} does not exist. Please upload the image to the specified path.\")\n",
        "        from google.colab import files\n",
        "        files.upload()\n",
        "        break\n",
        "\n",
        "# Directory to save augmented images\n",
        "augmented_dir = '/content/augmented'\n",
        "os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "img_width, img_height = 224, 224  # EfficientNetB0 input size\n",
        "batch_size = 32\n",
        "num_augmented = 850  # Number of augmented images per original image\n",
        "\n",
        "# Create ImageDataGenerator instances for healthy and impaired augmentations\n",
        "healthy_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    brightness_range=[0.8,1.2],\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "impaired_datagen = ImageDataGenerator(\n",
        "    rotation_range=45,  # More rotation to simulate impairments\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    brightness_range=[0.5,1.5],\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Function to augment images\n",
        "def augment_image(image_path, label, datagen, save_dir, prefix, num_augmented):\n",
        "    img = load_img(image_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    aug_iter = datagen.flow(\n",
        "        x,\n",
        "        batch_size=1,\n",
        "        save_to_dir=save_dir,\n",
        "        save_prefix=prefix,\n",
        "        save_format='png'\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i in range(num_augmented):\n",
        "        next(aug_iter)\n",
        "        labels.append(label)\n",
        "    return labels\n",
        "\n",
        "# Create directories for healthy and impaired images\n",
        "healthy_dir = os.path.join(augmented_dir, 'healthy')\n",
        "impaired_dir = os.path.join(augmented_dir, 'impaired')\n",
        "os.makedirs(healthy_dir, exist_ok=True)\n",
        "os.makedirs(impaired_dir, exist_ok=True)\n",
        "\n",
        "# Augment healthy images\n",
        "labels_healthy = []\n",
        "labels_healthy += augment_image(original_house, 0, healthy_datagen, healthy_dir, 'house_healthy', num_augmented)\n",
        "labels_healthy += augment_image(original_clock, 0, healthy_datagen, healthy_dir, 'clock_healthy', num_augmented)\n",
        "\n",
        "# Augment impaired images\n",
        "labels_impaired = []\n",
        "labels_impaired += augment_image(original_house, 1, impaired_datagen, impaired_dir, 'house_impaired', num_augmented)\n",
        "labels_impaired += augment_image(original_clock, 1, impaired_datagen, impaired_dir, 'clock_impaired', num_augmented)\n",
        "\n",
        "# Combine labels\n",
        "labels = labels_healthy + labels_impaired\n",
        "\n",
        "# Collect image file paths and corresponding labels\n",
        "image_paths = []\n",
        "for fname in os.listdir(healthy_dir):\n",
        "    if fname.endswith('.png'):\n",
        "        image_paths.append(os.path.join(healthy_dir, fname))\n",
        "for fname in os.listdir(impaired_dir):\n",
        "    if fname.endswith('.png'):\n",
        "        image_paths.append(os.path.join(impaired_dir, fname))\n",
        "\n",
        "# Shuffle the dataset\n",
        "combined = list(zip(image_paths, labels))\n",
        "random.shuffle(combined)\n",
        "image_paths, labels = zip(*combined)\n",
        "\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Map numerical labels to string labels\n",
        "label_mapping = {0: 'Healthy', 1: 'Impaired'}\n",
        "labels_str = np.array([label_mapping[label] for label in labels])\n",
        "\n",
        "# Create a dataframe with string labels\n",
        "full_df = pd.DataFrame({'filename': image_paths, 'class': labels_str})\n",
        "\n",
        "# Plot the distribution of classes\n",
        "plt.figure(figsize=(6,4))\n",
        "full_df['class'].value_counts().plot(kind='bar')\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()\n",
        "\n",
        "# Show some sample images\n",
        "def show_sample_images(df, title):\n",
        "    plt.figure(figsize=(12,6))\n",
        "    samples = df.sample(5)\n",
        "    for idx, row in enumerate(samples.iterrows()):\n",
        "        img_path = row[1]['filename']\n",
        "        img = load_img(img_path, target_size=(img_width, img_height))\n",
        "        plt.subplot(1,5,idx+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(row[1]['class'])\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "show_sample_images(full_df[full_df['class'] == 'Healthy'], 'Sample Healthy Images')\n",
        "show_sample_images(full_df[full_df['class'] == 'Impaired'], 'Sample Impaired Images')\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    full_df['filename'], full_df['class'], test_size=0.15, random_state=42, stratify=full_df['class'])\n",
        "\n",
        "# Create separate dataframes for training and validation\n",
        "train_df = pd.DataFrame({'filename': X_train, 'class': y_train})\n",
        "val_df = pd.DataFrame({'filename': X_val, 'class': y_val})\n",
        "\n",
        "print(f'Training samples: {len(train_df)}')\n",
        "print(f'Validation samples: {len(val_df)}')\n",
        "\n",
        "# Plot the distribution in training and validation sets\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "train_df['class'].value_counts().plot(kind='bar', ax=axs[0])\n",
        "axs[0].set_title('Training Set Class Distribution')\n",
        "axs[0].set_xlabel('Class')\n",
        "axs[0].set_ylabel('Number of Samples')\n",
        "\n",
        "val_df['class'].value_counts().plot(kind='bar', ax=axs[1])\n",
        "axs[1].set_title('Validation Set Class Distribution')\n",
        "axs[1].set_xlabel('Class')\n",
        "axs[1].set_ylabel('Number of Samples')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Define data generators with preprocessing\n",
        "train_datagen_flow = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n",
        "val_datagen_flow = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen_flow.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen_flow.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Class indices:\", train_generator.class_indices)\n",
        "\n",
        "# Build an Advanced CNN Model Using Transfer Learning (Functional API)\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.Input(shape=(img_width, img_height, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n",
        "\n",
        "# Fine-Tune the Model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except the top 20 layers\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define the number of fine-tuning epochs\n",
        "fine_tune_epochs = 10\n",
        "initial_epoch = len(history.history['loss'])\n",
        "total_epochs = initial_epoch + fine_tune_epochs\n",
        "\n",
        "# Continue training with fine-tuning\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=initial_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n",
        "\n",
        "# Load the best model saved during training\n",
        "best_model = tf.keras.models.load_model('/content/best_model.keras')\n",
        "\n",
        "# Function to preprocess and predict a single image\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Batch dimension\n",
        "    return img_array\n",
        "\n",
        "def predict_image(image_path, model):\n",
        "    preprocessed = preprocess_image(image_path)\n",
        "    prediction = model.predict(preprocessed)\n",
        "    class_idx = np.argmax(prediction, axis=1)[0]\n",
        "    class_label = 'Healthy' if class_idx == 0 else 'Impaired'\n",
        "    confidence = prediction[0][class_idx]\n",
        "    return class_label, confidence, prediction\n",
        "\n",
        "# Define test images\n",
        "test_images = [test_house, test_clock]\n",
        "\n",
        "# Function to calculate similarity metrics\n",
        "def calculate_similarity(original_path, test_path):\n",
        "    original = load_img(original_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    test = load_img(test_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "\n",
        "    original = img_to_array(original).astype('uint8')\n",
        "    test = img_to_array(test).astype('uint8')\n",
        "\n",
        "    # Convert to grayscale for SSIM\n",
        "    original_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)\n",
        "    test_gray = cv2.cvtColor(test, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Calculate SSIM\n",
        "    ssim_score = ssim(original_gray, test_gray)\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse_score = np.mean((original - test) ** 2)\n",
        "\n",
        "    return ssim_score, mse_score\n",
        "\n",
        "# Function to visualize comparison\n",
        "def visualize_comparison(original_path, test_path, title):\n",
        "    original = load_img(original_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    test = load_img(test_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "\n",
        "    original = img_to_array(original).astype('uint8')\n",
        "    test = img_to_array(test).astype('uint8')\n",
        "\n",
        "    # Calculate difference\n",
        "    difference = cv2.absdiff(original, test)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    difference_gray = cv2.cvtColor(difference, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply threshold to highlight differences\n",
        "    _, thresh = cv2.threshold(difference_gray, 30, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate SSIM for display\n",
        "    ssim_score, _ = calculate_similarity(original_path, test_path)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(15,5))\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(original.astype('uint8'))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(test.astype('uint8'))\n",
        "    plt.title('Test Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(thresh, cmap='gray')\n",
        "    plt.title(f'Difference Map\\nSSIM: {ssim_score:.4f}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "# Function to generate Grad-CAM heatmap\n",
        "def get_gradcam_heatmap(model, image_path):\n",
        "    # Load and preprocess the image\n",
        "    img = load_img(image_path, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Get the last convolutional layer\n",
        "    last_conv_layer = model.get_layer('efficientnetb0').get_layer('top_conv')\n",
        "\n",
        "    # Create a model that maps the input image to the activations of the last conv layer\n",
        "    grad_model = Model([model.inputs], [last_conv_layer.output, model.output])\n",
        "\n",
        "    # Compute the gradient of the top predicted class for the input image\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        predicted_class = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, predicted_class]\n",
        "\n",
        "    # Compute gradients\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    # Compute guided gradients\n",
        "    guided_grads = grads[0]\n",
        "\n",
        "    # Weigh the outputs of the conv layer with the gradients\n",
        "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs[0]), axis=-1)\n",
        "\n",
        "    # Apply ReLU to the heatmap\n",
        "    heatmap = np.maximum(cam, 0)\n",
        "    max_heat = np.max(heatmap)\n",
        "    if max_heat == 0:\n",
        "        max_heat = 1e-10\n",
        "    heatmap /= max_heat\n",
        "\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(image_path, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
        "    # Load the original image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (img_width, img_height))\n",
        "\n",
        "    # Resize heatmap to match the image size\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Convert to RGB\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap_colored = cv2.applyColorMap(heatmap, colormap)\n",
        "\n",
        "    # Superimpose the heatmap on the image\n",
        "    superimposed_img = cv2.addWeighted(heatmap_colored, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    # Convert BGR to RGB for displaying\n",
        "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function to generate analysis report\n",
        "def generate_analysis_report(original_path, test_path, model):\n",
        "    # Determine the drawing type\n",
        "    if 'house' in test_path.lower():\n",
        "        title = 'House Drawing Analysis'\n",
        "    elif 'clock' in test_path.lower():\n",
        "        title = 'Clock Drawing Analysis'\n",
        "    else:\n",
        "        title = 'Drawing Analysis'\n",
        "\n",
        "    # Predict label and confidence\n",
        "    label, conf, pred = predict_image(test_path, model)\n",
        "\n",
        "    # Calculate similarity metrics\n",
        "    ssim_score, mse_score = calculate_similarity(original_path, test_path)\n",
        "\n",
        "    # Display similarity metrics\n",
        "    print(f'--- {title} ---')\n",
        "    print(f'Predicted Label: {label} with confidence {conf:.2f}')\n",
        "    print(f'SSIM Score: {ssim_score:.4f}')\n",
        "    print(f'MSE Score: {mse_score:.2f}')\n",
        "    print('\\n')\n",
        "\n",
        "    # Visualize comparison\n",
        "    visualize_comparison(original_path, test_path, title)\n",
        "\n",
        "    # Generate Grad-CAM heatmap\n",
        "    try:\n",
        "        heatmap = get_gradcam_heatmap(model, test_path)\n",
        "        print('Grad-CAM Heatmap:')\n",
        "        display_gradcam(test_path, heatmap)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Grad-CAM: {e}\")\n",
        "\n",
        "    # Provide textual analysis\n",
        "    if label == 'Impaired':\n",
        "        print(\"Analysis: The drawing shows significant deviations from the original, indicating possible cognitive impairments associated with Alzheimer's disease.\")\n",
        "    else:\n",
        "        print(\"Analysis: The drawing closely resembles the original, suggesting no significant cognitive impairments detected.\")\n",
        "    print('\\n' + '='*80 + '\\n')\n",
        "\n",
        "# Generate analysis reports for test images\n",
        "for test_img in test_images:\n",
        "    if 'house' in test_img.lower():\n",
        "        original_img = original_house\n",
        "    elif 'clock' in test_img.lower():\n",
        "        original_img = original_clock\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    generate_analysis_report(original_img, test_img, best_model)\n",
        "\n",
        "# Plot Training and Validation Metrics\n",
        "def plot_training_history(history, fine_tune_history=None):\n",
        "    plt.figure(figsize=(14,6))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    epochs_range = range(len(history.history['accuracy']))\n",
        "    plt.plot(epochs_range, history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "\n",
        "    if fine_tune_history:\n",
        "        fine_tune_epochs_range = range(len(history.history['accuracy']), len(history.history['accuracy']) + len(fine_tune_history.history['accuracy']))\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['accuracy'], label='Fine-Tune Train Accuracy')\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['val_accuracy'], label='Fine-Tune Validation Accuracy')\n",
        "\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs_range, history.history['loss'], label='Train Loss')\n",
        "    plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss')\n",
        "\n",
        "    if fine_tune_history:\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['loss'], label='Fine-Tune Train Loss')\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['val_loss'], label='Fine-Tune Validation Loss')\n",
        "\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training history\n",
        "plot_training_history(history, history_fine)\n"
      ],
      "metadata": {
        "id": "voN8xFmDmwRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (optional, if you're saving or loading files from Google Drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import Necessary Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Define paths to the original and test images\n",
        "original_house = '/content/house.png'\n",
        "original_clock = '/content/clock.png'\n",
        "\n",
        "test_house = '/content/house_test.png'\n",
        "test_clock = '/content/clock_test.png'\n",
        "\n",
        "# Ensure the images exist\n",
        "required_images = [original_house, original_clock, test_house, test_clock]\n",
        "for img_path in required_images:\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"Error: {img_path} does not exist. Please upload the image to the specified path.\")\n",
        "        from google.colab import files\n",
        "        files.upload()\n",
        "        break\n",
        "\n",
        "# Directory to save augmented images\n",
        "augmented_dir = '/content/augmented'\n",
        "os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "img_width, img_height = 224, 224  # EfficientNetB0 input size\n",
        "num_augmented = 850  # Number of augmented images per original image\n",
        "\n",
        "# Function to simulate impairment by removing or misplacing parts of the image\n",
        "def impair_image(image_path, save_dir, prefix, num_augmented):\n",
        "    img = Image.open(image_path).resize((img_width, img_height))\n",
        "    labels = []\n",
        "    for i in range(num_augmented):\n",
        "        impaired_img = img.copy()\n",
        "        draw = ImageDraw.Draw(impaired_img)\n",
        "\n",
        "        # Decide how many parts to remove (e.g., 20% to 50% of the elements)\n",
        "        num_parts_to_remove = random.randint(3, 7)\n",
        "\n",
        "        for _ in range(num_parts_to_remove):\n",
        "            # Randomly select a rectangle region to remove\n",
        "            x1 = random.randint(0, img_width - 50)\n",
        "            y1 = random.randint(0, img_height - 50)\n",
        "            x2 = x1 + random.randint(20, 70)\n",
        "            y2 = y1 + random.randint(20, 70)\n",
        "            draw.rectangle([x1, y1, x2, y2], fill=(255, 255, 255))\n",
        "\n",
        "        # Misplace elements by drawing random shapes\n",
        "        num_parts_to_misplace = random.randint(1, 3)\n",
        "        for _ in range(num_parts_to_misplace):\n",
        "            shape_type = random.choice(['rectangle', 'ellipse'])\n",
        "            x1 = random.randint(0, img_width - 50)\n",
        "            y1 = random.randint(0, img_height - 50)\n",
        "            x2 = x1 + random.randint(20, 70)\n",
        "            y2 = y1 + random.randint(20, 70)\n",
        "            if shape_type == 'rectangle':\n",
        "                draw.rectangle([x1, y1, x2, y2], fill=(0, 0, 0))\n",
        "            else:\n",
        "                draw.ellipse([x1, y1, x2, y2], fill=(0, 0, 0))\n",
        "\n",
        "        # Save the impaired image\n",
        "        impaired_img.save(os.path.join(save_dir, f\"{prefix}_{i}.png\"))\n",
        "        labels.append(1)  # Label 1 for impaired\n",
        "    return labels\n",
        "\n",
        "# Function to simulate healthy images with slight augmentations\n",
        "def healthy_image(image_path, datagen, save_dir, prefix, num_augmented):\n",
        "    img = load_img(image_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Create an iterator for data augmentation\n",
        "    aug_iter = datagen.flow(\n",
        "        x,\n",
        "        batch_size=1,\n",
        "        save_to_dir=save_dir,\n",
        "        save_prefix=prefix,\n",
        "        save_format='png'\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i in range(num_augmented):\n",
        "        next(aug_iter)\n",
        "        labels.append(0)  # Label 0 for healthy\n",
        "    return labels\n",
        "\n",
        "# Create ImageDataGenerator instance for healthy images with slight augmentations\n",
        "healthy_datagen = ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    zoom_range=0.05,\n",
        "    shear_range=0.05,\n",
        "    brightness_range=[0.9,1.1],\n",
        "    horizontal_flip=False,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Create directories for healthy and impaired images\n",
        "healthy_dir = os.path.join(augmented_dir, 'healthy')\n",
        "impaired_dir = os.path.join(augmented_dir, 'impaired')\n",
        "os.makedirs(healthy_dir, exist_ok=True)\n",
        "os.makedirs(impaired_dir, exist_ok=True)\n",
        "\n",
        "# Generate healthy images\n",
        "labels_healthy = []\n",
        "labels_healthy += healthy_image(original_house, healthy_datagen, healthy_dir, 'house_healthy', num_augmented)\n",
        "labels_healthy += healthy_image(original_clock, healthy_datagen, healthy_dir, 'clock_healthy', num_augmented)\n",
        "\n",
        "# Generate impaired images\n",
        "labels_impaired = []\n",
        "labels_impaired += impair_image(original_house, impaired_dir, 'house_impaired', num_augmented)\n",
        "labels_impaired += impair_image(original_clock, impaired_dir, 'clock_impaired', num_augmented)\n",
        "\n",
        "# Combine labels\n",
        "labels = labels_healthy + labels_impaired\n",
        "\n",
        "# Collect image file paths and corresponding labels\n",
        "image_paths = []\n",
        "for fname in os.listdir(healthy_dir):\n",
        "    if fname.endswith('.png'):\n",
        "        image_paths.append(os.path.join(healthy_dir, fname))\n",
        "for fname in os.listdir(impaired_dir):\n",
        "    if fname.endswith('.png'):\n",
        "        image_paths.append(os.path.join(impaired_dir, fname))\n",
        "\n",
        "# Shuffle the dataset\n",
        "combined = list(zip(image_paths, labels))\n",
        "random.shuffle(combined)\n",
        "image_paths, labels = zip(*combined)\n",
        "\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Map numerical labels to string labels\n",
        "label_mapping = {0: 'Healthy', 1: 'Impaired'}\n",
        "labels_str = np.array([label_mapping[label] for label in labels])\n",
        "\n",
        "# Create a dataframe with string labels\n",
        "full_df = pd.DataFrame({'filename': image_paths, 'class': labels_str})\n",
        "\n",
        "# Plot the distribution of classes\n",
        "plt.figure(figsize=(6,4))\n",
        "full_df['class'].value_counts().plot(kind='bar')\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()\n",
        "\n",
        "# Show some sample images\n",
        "def show_sample_images(df, title):\n",
        "    plt.figure(figsize=(12,6))\n",
        "    samples = df.sample(5)\n",
        "    for idx, row in enumerate(samples.iterrows()):\n",
        "        img_path = row[1]['filename']\n",
        "        img = load_img(img_path, target_size=(img_width, img_height))\n",
        "        plt.subplot(1,5,idx+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(row[1]['class'])\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "show_sample_images(full_df[full_df['class'] == 'Healthy'], 'Sample Healthy Images')\n",
        "show_sample_images(full_df[full_df['class'] == 'Impaired'], 'Sample Impaired Images')\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    full_df['filename'], full_df['class'], test_size=0.15, random_state=42, stratify=full_df['class'])\n",
        "\n",
        "# Create separate dataframes for training and validation\n",
        "train_df = pd.DataFrame({'filename': X_train, 'class': y_train})\n",
        "val_df = pd.DataFrame({'filename': X_val, 'class': y_val})\n",
        "\n",
        "print(f'Training samples: {len(train_df)}')\n",
        "print(f'Validation samples: {len(val_df)}')\n",
        "\n",
        "# Plot the distribution in training and validation sets\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "train_df['class'].value_counts().plot(kind='bar', ax=axs[0])\n",
        "axs[0].set_title('Training Set Class Distribution')\n",
        "axs[0].set_xlabel('Class')\n",
        "axs[0].set_ylabel('Number of Samples')\n",
        "\n",
        "val_df['class'].value_counts().plot(kind='bar', ax=axs[1])\n",
        "axs[1].set_title('Validation Set Class Distribution')\n",
        "axs[1].set_xlabel('Class')\n",
        "axs[1].set_ylabel('Number of Samples')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Define data generators with preprocessing\n",
        "train_datagen_flow = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n",
        "val_datagen_flow = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen_flow.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen_flow.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Class indices:\", train_generator.class_indices)\n",
        "\n",
        "# Build an Advanced CNN Model Using Transfer Learning (Functional API)\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.Input(shape=(img_width, img_height, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n",
        "\n",
        "# Fine-Tune the Model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except the top 20 layers\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Continue training with fine-tuning\n",
        "fine_tune_epochs = 10\n",
        "initial_epoch = len(history.history['loss'])\n",
        "total_epochs = initial_epoch + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=initial_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n",
        "\n",
        "# Load the best model saved during training\n",
        "best_model = tf.keras.models.load_model('/content/best_model.keras')\n",
        "\n",
        "# Function to preprocess and predict a single image\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Batch dimension\n",
        "    return img_array\n",
        "\n",
        "def predict_image(image_path, model):\n",
        "    preprocessed = preprocess_image(image_path)\n",
        "    prediction = model.predict(preprocessed)\n",
        "    class_idx = np.argmax(prediction, axis=1)[0]\n",
        "    class_label = 'Healthy' if class_idx == 0 else 'Impaired'\n",
        "    confidence = prediction[0][class_idx]\n",
        "    return class_label, confidence, prediction\n",
        "\n",
        "# Function to calculate missing parts percentage\n",
        "def detect_missing_parts(original_path, test_path):\n",
        "    # Load images in grayscale\n",
        "    original = cv2.imread(original_path, cv2.IMREAD_GRAYSCALE)\n",
        "    test = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Resize images to the same size\n",
        "    original = cv2.resize(original, (img_width, img_height))\n",
        "    test = cv2.resize(test, (img_width, img_height))\n",
        "\n",
        "    # Apply threshold to binarize images\n",
        "    _, original_thresh = cv2.threshold(original, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "    _, test_thresh = cv2.threshold(test, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the images\n",
        "    contours_original, _ = cv2.findContours(original_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours_test, _ = cv2.findContours(test_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Create blank images to draw contours\n",
        "    original_contour_img = np.zeros_like(original_thresh)\n",
        "    test_contour_img = np.zeros_like(test_thresh)\n",
        "\n",
        "    # Draw contours\n",
        "    cv2.drawContours(original_contour_img, contours_original, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
        "    cv2.drawContours(test_contour_img, contours_test, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
        "\n",
        "    # Calculate the difference\n",
        "    difference = cv2.absdiff(original_contour_img, test_contour_img)\n",
        "    missing_pixels = cv2.countNonZero(difference)\n",
        "    total_pixels = cv2.countNonZero(original_contour_img)\n",
        "\n",
        "    # Calculate missing parts percentage\n",
        "    if total_pixels == 0:\n",
        "        total_pixels = 1e-5  # Prevent division by zero\n",
        "    missing_percentage = (missing_pixels / total_pixels) * 100\n",
        "\n",
        "    return missing_percentage\n",
        "\n",
        "# Function to visualize comparison\n",
        "def visualize_comparison(original_path, test_path, title):\n",
        "    original = load_img(original_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    test = load_img(test_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "\n",
        "    original = img_to_array(original).astype('uint8')\n",
        "    test = img_to_array(test).astype('uint8')\n",
        "\n",
        "    # Calculate difference\n",
        "    difference = cv2.absdiff(original, test)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    difference_gray = cv2.cvtColor(difference, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply threshold to highlight differences\n",
        "    _, thresh = cv2.threshold(difference_gray, 30, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(15,5))\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(original.astype('uint8'))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(test.astype('uint8'))\n",
        "    plt.title('Test Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(thresh, cmap='gray')\n",
        "    plt.title('Difference Map')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "# Function to generate Grad-CAM heatmap\n",
        "def get_gradcam_heatmap(model, image_path):\n",
        "    # Load and preprocess the image\n",
        "    img = load_img(image_path, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Get the last convolutional layer\n",
        "    last_conv_layer = model.get_layer('efficientnetb0').get_layer('top_conv')\n",
        "\n",
        "    # Create a model that maps the input image to the activations of the last conv layer\n",
        "    grad_model = Model([model.inputs], [last_conv_layer.output, model.output])\n",
        "\n",
        "    # Compute the gradient of the top predicted class for the input image\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        predicted_class = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, predicted_class]\n",
        "\n",
        "    # Compute gradients\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    # Compute guided gradients\n",
        "    guided_grads = grads[0]\n",
        "\n",
        "    # Weigh the outputs of the conv layer with the gradients\n",
        "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs[0]), axis=-1)\n",
        "\n",
        "    # Apply ReLU to the heatmap\n",
        "    heatmap = np.maximum(cam, 0)\n",
        "    max_heat = np.max(heatmap)\n",
        "    if max_heat == 0:\n",
        "        max_heat = 1e-10\n",
        "    heatmap /= max_heat\n",
        "\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(image_path, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
        "    # Load the original image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (img_width, img_height))\n",
        "\n",
        "    # Resize heatmap to match the image size\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Convert to RGB\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap_colored = cv2.applyColorMap(heatmap, colormap)\n",
        "\n",
        "    # Superimpose the heatmap on the image\n",
        "    superimposed_img = cv2.addWeighted(heatmap_colored, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    # Convert BGR to RGB for displaying\n",
        "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function to generate analysis report\n",
        "def generate_analysis_report(original_path, test_path, model):\n",
        "    # Determine the drawing type\n",
        "    if 'house' in test_path.lower():\n",
        "        title = 'House Drawing Analysis'\n",
        "    elif 'clock' in test_path.lower():\n",
        "        title = 'Clock Drawing Analysis'\n",
        "    else:\n",
        "        title = 'Drawing Analysis'\n",
        "\n",
        "    # Predict label and confidence\n",
        "    label, conf, pred = predict_image(test_path, model)\n",
        "\n",
        "    # Calculate missing parts percentage\n",
        "    missing_percentage = detect_missing_parts(original_path, test_path)\n",
        "\n",
        "    # Display analysis\n",
        "    print(f'--- {title} ---')\n",
        "    print(f'Predicted Label: {label} with confidence {conf:.2f}')\n",
        "    print(f'Missing Parts Percentage: {missing_percentage:.2f}%')\n",
        "    print('\\n')\n",
        "\n",
        "    # Visualize comparison\n",
        "    visualize_comparison(original_path, test_path, title)\n",
        "\n",
        "    # Generate Grad-CAM heatmap\n",
        "    try:\n",
        "        heatmap = get_gradcam_heatmap(model, test_path)\n",
        "        print('Grad-CAM Heatmap:')\n",
        "        display_gradcam(test_path, heatmap)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Grad-CAM: {e}\")\n",
        "\n",
        "    # Provide textual analysis\n",
        "    if label == 'Impaired':\n",
        "        print(f\"Analysis: The drawing shows significant deviations with {missing_percentage:.2f}% missing or misplaced elements, indicating a higher possibility of cognitive impairments associated with Alzheimer's disease.\")\n",
        "    else:\n",
        "        print(f\"Analysis: The drawing closely resembles the original with {missing_percentage:.2f}% missing elements, suggesting no significant cognitive impairments detected.\")\n",
        "    print('\\n' + '='*80 + '\\n')\n",
        "\n",
        "# Generate analysis reports for test images\n",
        "test_images = [test_house, test_clock]\n",
        "for test_img in test_images:\n",
        "    if 'house' in test_img.lower():\n",
        "        original_img = original_house\n",
        "    elif 'clock' in test_img.lower():\n",
        "        original_img = original_clock\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    generate_analysis_report(original_img, test_img, best_model)\n",
        "\n",
        "# Plot Training and Validation Metrics\n",
        "def plot_training_history(history, fine_tune_history=None):\n",
        "    plt.figure(figsize=(14,6))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    epochs_range = range(len(history.history['accuracy']))\n",
        "    plt.plot(epochs_range, history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "\n",
        "    if fine_tune_history:\n",
        "        fine_tune_epochs_range = range(len(history.history['accuracy']), len(history.history['accuracy']) + len(fine_tune_history.history['accuracy']))\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['accuracy'], label='Fine-Tune Train Accuracy')\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['val_accuracy'], label='Fine-Tune Validation Accuracy')\n",
        "\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs_range, history.history['loss'], label='Train Loss')\n",
        "    plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss')\n",
        "\n",
        "    if fine_tune_history:\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['loss'], label='Fine-Tune Train Loss')\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['val_loss'], label='Fine-Tune Validation Loss')\n",
        "\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training history\n",
        "plot_training_history(history, history_fine)\n"
      ],
      "metadata": {
        "id": "n2yJ9uqBoqa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Necessary Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Define paths to the original and test images\n",
        "original_house = '/content/house.png'\n",
        "original_clock = '/content/clock.png'\n",
        "\n",
        "test_house = '/content/house_test.png'\n",
        "test_clock = '/content/clock_test.png'\n",
        "\n",
        "# Ensure the images exist\n",
        "required_images = [original_house, original_clock, test_house, test_clock]\n",
        "for img_path in required_images:\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"Error: {img_path} does not exist. Please upload the image to the specified path.\")\n",
        "        from google.colab import files\n",
        "        files.upload()\n",
        "        break\n",
        "\n",
        "# Directory to save augmented images\n",
        "augmented_dir = '/content/augmented'\n",
        "os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "img_width, img_height = 224, 224  # EfficientNetB0 input size\n",
        "num_augmented = 850  # Number of augmented images per original image\n",
        "\n",
        "# Function to simulate impairment by removing or misplacing parts of the image\n",
        "def impair_image(image_path, save_dir, prefix, num_augmented):\n",
        "    img = Image.open(image_path).resize((img_width, img_height))\n",
        "    labels = []\n",
        "    for i in range(num_augmented):\n",
        "        impaired_img = img.copy()\n",
        "        draw = ImageDraw.Draw(impaired_img)\n",
        "\n",
        "        # Decide how many parts to remove (e.g., 20% to 50% of the elements)\n",
        "        num_parts_to_remove = random.randint(3, 7)\n",
        "\n",
        "        for _ in range(num_parts_to_remove):\n",
        "            # Randomly select a rectangle region to remove\n",
        "            x1 = random.randint(0, img_width - 50)\n",
        "            y1 = random.randint(0, img_height - 50)\n",
        "            x2 = x1 + random.randint(20, 70)\n",
        "            y2 = y1 + random.randint(20, 70)\n",
        "            draw.rectangle([x1, y1, x2, y2], fill=(255, 255, 255))\n",
        "\n",
        "        # Misplace elements by drawing random shapes\n",
        "        num_parts_to_misplace = random.randint(1, 3)\n",
        "        for _ in range(num_parts_to_misplace):\n",
        "            shape_type = random.choice(['rectangle', 'ellipse'])\n",
        "            x1 = random.randint(0, img_width - 50)\n",
        "            y1 = random.randint(0, img_height - 50)\n",
        "            x2 = x1 + random.randint(20, 70)\n",
        "            y2 = y1 + random.randint(20, 70)\n",
        "            if shape_type == 'rectangle':\n",
        "                draw.rectangle([x1, y1, x2, y2], fill=(0, 0, 0))\n",
        "            else:\n",
        "                draw.ellipse([x1, y1, x2, y2], fill=(0, 0, 0))\n",
        "\n",
        "        # Save the impaired image\n",
        "        impaired_img.save(os.path.join(save_dir, f\"{prefix}_{i}.png\"))\n",
        "        labels.append(1)  # Label 1 for impaired\n",
        "    return labels\n",
        "\n",
        "# Function to simulate healthy images with slight augmentations\n",
        "def healthy_image(image_path, datagen, save_dir, prefix, num_augmented):\n",
        "    img = load_img(image_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Create an iterator for data augmentation\n",
        "    aug_iter = datagen.flow(\n",
        "        x,\n",
        "        batch_size=1,\n",
        "        save_to_dir=save_dir,\n",
        "        save_prefix=prefix,\n",
        "        save_format='png'\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i in range(num_augmented):\n",
        "        next(aug_iter)\n",
        "        labels.append(0)  # Label 0 for healthy\n",
        "    return labels\n",
        "\n",
        "# Create ImageDataGenerator instance for healthy images with slight augmentations\n",
        "healthy_datagen = ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    zoom_range=0.05,\n",
        "    shear_range=0.05,\n",
        "    brightness_range=[0.9,1.1],\n",
        "    horizontal_flip=False,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Create directories for healthy and impaired images\n",
        "healthy_dir = os.path.join(augmented_dir, 'healthy')\n",
        "impaired_dir = os.path.join(augmented_dir, 'impaired')\n",
        "os.makedirs(healthy_dir, exist_ok=True)\n",
        "os.makedirs(impaired_dir, exist_ok=True)\n",
        "\n",
        "# Generate healthy images\n",
        "labels_healthy = []\n",
        "labels_healthy += healthy_image(original_house, healthy_datagen, healthy_dir, 'house_healthy', num_augmented)\n",
        "labels_healthy += healthy_image(original_clock, healthy_datagen, healthy_dir, 'clock_healthy', num_augmented)\n",
        "\n",
        "# Generate impaired images\n",
        "labels_impaired = []\n",
        "labels_impaired += impair_image(original_house, impaired_dir, 'house_impaired', num_augmented)\n",
        "labels_impaired += impair_image(original_clock, impaired_dir, 'clock_impaired', num_augmented)\n",
        "\n",
        "# Combine labels\n",
        "labels = labels_healthy + labels_impaired\n",
        "\n",
        "# Collect image file paths and corresponding labels\n",
        "image_paths = []\n",
        "for fname in os.listdir(healthy_dir):\n",
        "    if fname.endswith('.png'):\n",
        "        image_paths.append(os.path.join(healthy_dir, fname))\n",
        "for fname in os.listdir(impaired_dir):\n",
        "    if fname.endswith('.png'):\n",
        "        image_paths.append(os.path.join(impaired_dir, fname))\n",
        "\n",
        "# Shuffle the dataset\n",
        "combined = list(zip(image_paths, labels))\n",
        "random.shuffle(combined)\n",
        "image_paths, labels = zip(*combined)\n",
        "\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Map numerical labels to string labels\n",
        "label_mapping = {0: 'Healthy', 1: 'Impaired'}\n",
        "labels_str = np.array([label_mapping[label] for label in labels])\n",
        "\n",
        "# Create a dataframe with string labels\n",
        "full_df = pd.DataFrame({'filename': image_paths, 'class': labels_str})\n",
        "\n",
        "# Plot the distribution of classes\n",
        "plt.figure(figsize=(6,4))\n",
        "full_df['class'].value_counts().plot(kind='bar', color=['green', 'red'])\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "# Show some sample images\n",
        "def show_sample_images(df, title):\n",
        "    plt.figure(figsize=(15,6))\n",
        "    samples = df.sample(5)\n",
        "    for idx, row in enumerate(samples.iterrows()):\n",
        "        img_path = row[1]['filename']\n",
        "        img = load_img(img_path, target_size=(img_width, img_height))\n",
        "        plt.subplot(1,5,idx+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(row[1]['class'])\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "show_sample_images(full_df[full_df['class'] == 'Healthy'], 'Sample Healthy Images')\n",
        "show_sample_images(full_df[full_df['class'] == 'Impaired'], 'Sample Impaired Images')\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    full_df['filename'], full_df['class'], test_size=0.15, random_state=42, stratify=full_df['class'])\n",
        "\n",
        "# Create separate dataframes for training and validation\n",
        "train_df = pd.DataFrame({'filename': X_train, 'class': y_train})\n",
        "val_df = pd.DataFrame({'filename': X_val, 'class': y_val})\n",
        "\n",
        "print(f'Training samples: {len(train_df)}')\n",
        "print(f'Validation samples: {len(val_df)}')\n",
        "\n",
        "# Plot the distribution in training and validation sets\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "train_df['class'].value_counts().plot(kind='bar', ax=axs[0], color=['green', 'red'])\n",
        "axs[0].set_title('Training Set Class Distribution')\n",
        "axs[0].set_xlabel('Class')\n",
        "axs[0].set_ylabel('Number of Samples')\n",
        "axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=0)\n",
        "\n",
        "val_df['class'].value_counts().plot(kind='bar', ax=axs[1], color=['green', 'red'])\n",
        "axs[1].set_title('Validation Set Class Distribution')\n",
        "axs[1].set_xlabel('Class')\n",
        "axs[1].set_ylabel('Number of Samples')\n",
        "axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Define data generators with preprocessing\n",
        "train_datagen_flow = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n",
        "val_datagen_flow = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen_flow.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen_flow.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Class indices:\", train_generator.class_indices)\n",
        "\n",
        "# Build an Advanced CNN Model Using Transfer Learning (Functional API)\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.Input(shape=(img_width, img_height, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n",
        "\n",
        "# Fine-Tune the Model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except the top 20 layers\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Continue training with fine-tuning\n",
        "fine_tune_epochs = 10\n",
        "initial_epoch = len(history.history['loss'])\n",
        "total_epochs = initial_epoch + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=initial_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n",
        "\n",
        "# Load the best model saved during training\n",
        "best_model = tf.keras.models.load_model('/content/best_model.keras')\n",
        "\n",
        "# Function to preprocess and predict a single image\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Batch dimension\n",
        "    return img_array\n",
        "\n",
        "def predict_image(image_path, model):\n",
        "    preprocessed = preprocess_image(image_path)\n",
        "    prediction = model.predict(preprocessed)\n",
        "    class_idx = np.argmax(prediction, axis=1)[0]\n",
        "    class_label = 'Healthy' if class_idx == 0 else 'Impaired'\n",
        "    confidence = prediction[0][class_idx]\n",
        "    return class_label, confidence, prediction\n",
        "\n",
        "# Function to calculate missing parts percentage\n",
        "def detect_missing_parts(original_path, test_path):\n",
        "    # Load images in grayscale\n",
        "    original = cv2.imread(original_path, cv2.IMREAD_GRAYSCALE)\n",
        "    test = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Resize images to the same size\n",
        "    original = cv2.resize(original, (img_width, img_height))\n",
        "    test = cv2.resize(test, (img_width, img_height))\n",
        "\n",
        "    # Apply threshold to binarize images\n",
        "    _, original_thresh = cv2.threshold(original, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "    _, test_thresh = cv2.threshold(test, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the images\n",
        "    contours_original, _ = cv2.findContours(original_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours_test, _ = cv2.findContours(test_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Create blank images to draw contours\n",
        "    original_contour_img = np.zeros_like(original_thresh)\n",
        "    test_contour_img = np.zeros_like(test_thresh)\n",
        "\n",
        "    # Draw contours\n",
        "    cv2.drawContours(original_contour_img, contours_original, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
        "    cv2.drawContours(test_contour_img, contours_test, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
        "\n",
        "    # Calculate the difference\n",
        "    difference = cv2.absdiff(original_contour_img, test_contour_img)\n",
        "    missing_pixels = cv2.countNonZero(difference)\n",
        "    total_pixels = cv2.countNonZero(original_contour_img)\n",
        "\n",
        "    # Calculate missing parts percentage\n",
        "    if total_pixels == 0:\n",
        "        total_pixels = 1e-5  # Prevent division by zero\n",
        "    missing_percentage = (missing_pixels / total_pixels) * 100\n",
        "\n",
        "    return missing_percentage\n",
        "\n",
        "# Function to visualize comparison\n",
        "def visualize_comparison(original_path, test_path, title):\n",
        "    original = load_img(original_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "    test = load_img(test_path, color_mode='rgb', target_size=(img_width, img_height))\n",
        "\n",
        "    original = img_to_array(original).astype('uint8')\n",
        "    test = img_to_array(test).astype('uint8')\n",
        "\n",
        "    # Calculate difference\n",
        "    difference = cv2.absdiff(original, test)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    difference_gray = cv2.cvtColor(difference, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply threshold to highlight differences\n",
        "    _, thresh = cv2.threshold(difference_gray, 30, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(20,6))\n",
        "\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(original.astype('uint8'))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(test.astype('uint8'))\n",
        "    plt.title('Test Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(thresh, cmap='gray')\n",
        "    plt.title('Difference Map')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Overlay difference on test image\n",
        "    overlay = test.copy()\n",
        "    overlay[thresh > 0] = [255, 0, 0]  # Highlight differences in red\n",
        "\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.imshow(overlay.astype('uint8'))\n",
        "    plt.title('Highlighted Differences')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.suptitle(title, fontsize=18)\n",
        "    plt.show()\n",
        "\n",
        "# Function to generate Grad-CAM heatmap\n",
        "def get_gradcam_heatmap(model, image_path):\n",
        "    # Load and preprocess the image\n",
        "    img = load_img(image_path, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Get the last convolutional layer\n",
        "    last_conv_layer = model.get_layer('efficientnetb0').get_layer('top_conv')\n",
        "\n",
        "    # Create a model that maps the input image to the activations of the last conv layer\n",
        "    grad_model = Model([model.inputs], [last_conv_layer.output, model.output])\n",
        "\n",
        "    # Compute the gradient of the top predicted class for the input image\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        predicted_class = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, predicted_class]\n",
        "\n",
        "    # Compute gradients\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    # Compute guided gradients\n",
        "    guided_grads = grads[0]\n",
        "\n",
        "    # Weigh the outputs of the conv layer with the gradients\n",
        "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs[0]), axis=-1)\n",
        "\n",
        "    # Apply ReLU to the heatmap\n",
        "    heatmap = np.maximum(cam, 0)\n",
        "    max_heat = np.max(heatmap)\n",
        "    if max_heat == 0:\n",
        "        max_heat = 1e-10\n",
        "    heatmap /= max_heat\n",
        "\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(image_path, heatmap, alpha=0.6, colormap=cv2.COLORMAP_JET):\n",
        "    # Load the original image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (img_width, img_height))\n",
        "\n",
        "    # Resize heatmap to match the image size\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Convert to RGB\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap_colored = cv2.applyColorMap(heatmap, colormap)\n",
        "\n",
        "    # Superimpose the heatmap on the image\n",
        "    superimposed_img = cv2.addWeighted(heatmap_colored, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    # Convert BGR to RGB for displaying\n",
        "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.title('Grad-CAM Heatmap')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function to generate analysis report\n",
        "def generate_analysis_report(original_path, test_path, model):\n",
        "    # Determine the drawing type\n",
        "    if 'house' in test_path.lower():\n",
        "        title = 'House Drawing Analysis'\n",
        "    elif 'clock' in test_path.lower():\n",
        "        title = 'Clock Drawing Analysis'\n",
        "    else:\n",
        "        title = 'Drawing Analysis'\n",
        "\n",
        "    # Predict label and confidence\n",
        "    label, conf, pred = predict_image(test_path, model)\n",
        "\n",
        "    # Calculate missing parts percentage\n",
        "    missing_percentage = detect_missing_parts(original_path, test_path)\n",
        "\n",
        "    # Display analysis\n",
        "    print(f'--- {title} ---')\n",
        "    print(f'Predicted Label: {label} (Confidence: {conf*100:.2f}%)')\n",
        "    print(f'Missing Parts Percentage: {missing_percentage:.2f}%')\n",
        "    print('\\nDetailed Analysis:')\n",
        "\n",
        "    if missing_percentage < 10:\n",
        "        severity = 'low'\n",
        "    elif missing_percentage < 30:\n",
        "        severity = 'moderate'\n",
        "    else:\n",
        "        severity = 'high'\n",
        "\n",
        "    print(f\"- The drawing has a {severity} level of missing or misplaced elements.\")\n",
        "    print(f\"- {missing_percentage:.2f}% of the original drawing elements are missing or altered.\")\n",
        "    print(f\"- This indicates a {severity} possibility of cognitive impairments associated with Alzheimer's disease.\")\n",
        "\n",
        "    print('\\nVisual Comparisons:')\n",
        "    visualize_comparison(original_path, test_path, title)\n",
        "\n",
        "    # Generate Grad-CAM heatmap\n",
        "    try:\n",
        "        heatmap = get_gradcam_heatmap(model, test_path)\n",
        "        display_gradcam(test_path, heatmap)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Grad-CAM: {e}\")\n",
        "\n",
        "    print('\\n' + '='*100 + '\\n')\n",
        "\n",
        "# Generate analysis reports for test images\n",
        "test_images = [test_house, test_clock]\n",
        "for test_img in test_images:\n",
        "    if 'house' in test_img.lower():\n",
        "        original_img = original_house\n",
        "    elif 'clock' in test_img.lower():\n",
        "        original_img = original_clock\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    generate_analysis_report(original_img, test_img, best_model)\n",
        "\n",
        "# Plot Training and Validation Metrics\n",
        "def plot_training_history(history, fine_tune_history=None):\n",
        "    plt.figure(figsize=(14,6))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    epochs_range = range(len(history.history['accuracy']))\n",
        "    plt.plot(epochs_range, history.history['accuracy'], label='Train Accuracy', color='blue')\n",
        "    plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
        "\n",
        "    if fine_tune_history:\n",
        "        fine_tune_epochs_range = range(len(history.history['accuracy']), len(history.history['accuracy']) + len(fine_tune_history.history['accuracy']))\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['accuracy'], label='Fine-Tune Train Accuracy', color='green')\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['val_accuracy'], label='Fine-Tune Validation Accuracy', color='red')\n",
        "\n",
        "    plt.title('Training and Validation Accuracy', fontsize=16)\n",
        "    plt.xlabel('Epoch', fontsize=14)\n",
        "    plt.ylabel('Accuracy', fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs_range, history.history['loss'], label='Train Loss', color='blue')\n",
        "    plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss', color='orange')\n",
        "\n",
        "    if fine_tune_history:\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['loss'], label='Fine-Tune Train Loss', color='green')\n",
        "        plt.plot(fine_tune_epochs_range, fine_tune_history.history['val_loss'], label='Fine-Tune Validation Loss', color='red')\n",
        "\n",
        "    plt.title('Training and Validation Loss', fontsize=16)\n",
        "    plt.xlabel('Epoch', fontsize=14)\n",
        "    plt.ylabel('Loss', fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training history\n",
        "plot_training_history(history, history_fine)\n"
      ],
      "metadata": {
        "id": "McW-Ol5pqe3N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}